{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a5884bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'fastText' already exists and is not an empty directory.\n",
      "/Users/alitaylanakyurek/Downloads/Assigment_1/fastText\n",
      "Processing /Users/alitaylanakyurek/Downloads/Assigment_1/fastText\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages (from fasttext==0.9.2) (2.10.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages (from fasttext==0.9.2) (65.6.3)\n",
      "Requirement already satisfied: numpy in /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages (from fasttext==0.9.2) (1.24.2)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-macosx_10_16_x86_64.whl size=353716 sha256=e5c1f8611edd28a32c84ae54367a712b23c7c275d82878a29faa911fed32a475\n",
      "  Stored in directory: /private/var/folders/84/xkfrxtbd2hsbzdg1twbdsq340000gn/T/pip-ephem-wheel-cache-bxu4q6fw/wheels/ee/07/01/3fd810fc38316f3132f4095687872e0a36026c7e64d27dfa30\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "  Attempting uninstall: fasttext\n",
      "    Found existing installation: fasttext 0.9.2\n",
      "    Uninstalling fasttext-0.9.2:\n",
      "      Successfully uninstalled fasttext-0.9.2\n",
      "Successfully installed fasttext-0.9.2\n",
      "/Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages/setuptools/dist.py:770: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  warnings.warn(\n",
      "running install\n",
      "/Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing python/fasttext_module/fasttext.egg-info/PKG-INFO\n",
      "writing dependency_links to python/fasttext_module/fasttext.egg-info/dependency_links.txt\n",
      "writing requirements to python/fasttext_module/fasttext.egg-info/requires.txt\n",
      "writing top-level names to python/fasttext_module/fasttext.egg-info/top_level.txt\n",
      "reading manifest file 'python/fasttext_module/fasttext.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "warning: no files found matching 'PATENTS'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'python/fasttext_module/fasttext.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.macosx-10.9-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "running build_ext\n",
      "gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include -arch x86_64 -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include -arch x86_64 -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include/python3.8 -c /var/folders/84/xkfrxtbd2hsbzdg1twbdsq340000gn/T/tmp6sfmxywu.cpp -o var/folders/84/xkfrxtbd2hsbzdg1twbdsq340000gn/T/tmp6sfmxywu.o -stdlib=libc++\n",
      "gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include -arch x86_64 -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include -arch x86_64 -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include/python3.8 -c /var/folders/84/xkfrxtbd2hsbzdg1twbdsq340000gn/T/tmpyu93mfo9.cpp -o var/folders/84/xkfrxtbd2hsbzdg1twbdsq340000gn/T/tmpyu93mfo9.o -std=c++11\n",
      "gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include -arch x86_64 -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include -arch x86_64 -I/Users/alitaylanakyurek/anaconda3/envs/olartik/include/python3.8 -c /var/folders/84/xkfrxtbd2hsbzdg1twbdsq340000gn/T/tmpwyz43_pl.cpp -o var/folders/84/xkfrxtbd2hsbzdg1twbdsq340000gn/T/tmpwyz43_pl.o -fvisibility=hidden\n",
      "creating build/bdist.macosx-10.9-x86_64/egg\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext_pybind.cpython-38-darwin.so -> build/bdist.macosx-10.9-x86_64/egg\n",
      "creating build/bdist.macosx-10.9-x86_64/egg/fasttext\n",
      "creating build/bdist.macosx-10.9-x86_64/egg/fasttext/util\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext/util/util.py -> build/bdist.macosx-10.9-x86_64/egg/fasttext/util\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext/util/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/fasttext/util\n",
      "creating build/bdist.macosx-10.9-x86_64/egg/fasttext/tests\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext/tests/test_script.py -> build/bdist.macosx-10.9-x86_64/egg/fasttext/tests\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext/tests/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/fasttext/tests\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext/tests/test_configurations.py -> build/bdist.macosx-10.9-x86_64/egg/fasttext/tests\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/fasttext\n",
      "copying build/lib.macosx-10.9-x86_64-cpython-38/fasttext/FastText.py -> build/bdist.macosx-10.9-x86_64/egg/fasttext\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext/util/util.py to util.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext/util/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext/tests/test_script.py to test_script.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext/tests/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext/tests/test_configurations.py to test_configurations.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext/FastText.py to FastText.cpython-38.pyc\n",
      "creating stub loader for fasttext_pybind.cpython-38-darwin.so\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/fasttext_pybind.py to fasttext_pybind.cpython-38.pyc\n",
      "creating build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying python/fasttext_module/fasttext.egg-info/PKG-INFO -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying python/fasttext_module/fasttext.egg-info/SOURCES.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying python/fasttext_module/fasttext.egg-info/dependency_links.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying python/fasttext_module/fasttext.egg-info/not-zip-safe -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying python/fasttext_module/fasttext.egg-info/requires.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying python/fasttext_module/fasttext.egg-info/top_level.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.macosx-10.9-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "creating 'dist/fasttext-0.9.2-py3.8-macosx-10.9-x86_64.egg' and adding 'build/bdist.macosx-10.9-x86_64/egg' to it\n",
      "removing 'build/bdist.macosx-10.9-x86_64/egg' (and everything under it)\n",
      "Processing fasttext-0.9.2-py3.8-macosx-10.9-x86_64.egg\n",
      "removing '/Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages/fasttext-0.9.2-py3.8-macosx-10.9-x86_64.egg' (and everything under it)\n",
      "creating /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages/fasttext-0.9.2-py3.8-macosx-10.9-x86_64.egg\n",
      "Extracting fasttext-0.9.2-py3.8-macosx-10.9-x86_64.egg to /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages\n",
      "fasttext 0.9.2 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages/fasttext-0.9.2-py3.8-macosx-10.9-x86_64.egg\n",
      "Processing dependencies for fasttext==0.9.2\n",
      "Searching for numpy==1.24.2\n",
      "Best match: numpy 1.24.2\n",
      "Adding numpy 1.24.2 to easy-install.pth file\n",
      "Installing f2py script to /Users/alitaylanakyurek/anaconda3/envs/olartik/bin\n",
      "Installing f2py3 script to /Users/alitaylanakyurek/anaconda3/envs/olartik/bin\n",
      "Installing f2py3.8 script to /Users/alitaylanakyurek/anaconda3/envs/olartik/bin\n",
      "\n",
      "Using /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages\n",
      "Searching for setuptools==65.6.3\n",
      "Best match: setuptools 65.6.3\n",
      "Adding setuptools 65.6.3 to easy-install.pth file\n",
      "\n",
      "Using /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages\n",
      "Searching for pybind11==2.10.4\n",
      "Best match: pybind11 2.10.4\n",
      "Adding pybind11 2.10.4 to easy-install.pth file\n",
      "Installing pybind11-config script to /Users/alitaylanakyurek/anaconda3/envs/olartik/bin\n",
      "\n",
      "Using /Users/alitaylanakyurek/anaconda3/envs/olartik/lib/python3.8/site-packages\n",
      "Finished processing dependencies for fasttext==0.9.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alitaylanakyurek/Downloads/Assigment_1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/fastText.git\n",
    "%cd fastText\n",
    "!pip install .\n",
    "!python setup.py install\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1055762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if installation was successful\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5429a1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'wikifil'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 12\u001b[K\n",
      "Receiving objects: 100% (12/12), done.\n",
      "Resolving deltas: 100% (1/1), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hghodrati/wikifil.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13d2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess xml and save to new file\n",
    "!perl wikifil/wikifil.pl dataset/trwiki-20230401-pages-articles-multistream.xml > dataset/data_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6d4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " one one six two do um yeri onon nehri d l n boldak mo olistan l m tarihi l m y"
     ]
    }
   ],
   "source": [
    "# Visualize data\n",
    "!head -c 80 dataset/data_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec6f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: results: File exists\r\n"
     ]
    }
   ],
   "source": [
    "%mkdir results\n",
    "CBOW_EMBED = \"results/embed_cbow.bin\"\n",
    "SKIPGRAM_EMBED = \"results/embed_skipgram.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 247M words\n",
      "Number of words:  443672\n",
      "Number of labels: 0\n",
      "Progress:   0.8% words/sec/thread:  150013 lr:  0.049624 avg.loss:  1.940438 ETA:   0h45m29s"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "# Train the CBOW model\n",
    "embed_model_cbow = fasttext.train_unsupervised('dataset/data_embed', model='cbow')\n",
    "embed_model_cbow.save_model(CBOW_EMBED)\n",
    "embed_model_cbow = fasttext.load_model(CBOW_EMBED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921104fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_cbow = fasttext.load_model(CBOW_EMBED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5980f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(embed_model_cbow.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d579728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.294296   -1.880908    3.866084   -0.53450984 -0.746529    1.2178588\n",
      " -1.508628    5.126393    4.724427    1.326548   -3.1210868  -0.05586785\n",
      "  3.1144812   2.345092   -3.872583   -3.8402267  -1.4458805  -2.4879267\n",
      " -5.706722    0.3979774  -0.01078974 -0.19841765 -3.4739966   0.12982167\n",
      " -2.3909354  -0.27577567 -0.78161     1.8083713  -3.041014   -2.7527332\n",
      " -1.3530577   1.8920608  -2.2907948  -1.4107292  -0.8124462  -2.4625294\n",
      "  1.0520375   5.3012066  -1.5035663   0.15662003 -0.25623044 -3.2469213\n",
      " -2.0428581   1.5839351   1.4489285   3.18555     3.4286888  -0.6306196\n",
      " -0.43345064  0.17236225 -0.80951196  1.8966606   3.1868393   1.1018137\n",
      "  3.5887115   2.4989686   0.02336156 -2.594473    2.9108121  -0.07575616\n",
      "  1.1116657   3.7941074   5.2764163   0.99557275 -0.3277472   1.095738\n",
      "  4.4159336  -0.38141736 -3.6937728   1.02839     2.1005235  -3.070873\n",
      " -3.3441906  -0.23965181  0.59716076 -1.195617    0.7714918   2.3524938\n",
      " -2.861599   -3.3698997  -0.88416934  2.0075004  -2.7597904  -0.02217024\n",
      " -2.2821712  -7.7566767  -5.4268346   4.1134953   2.2448065  -5.046139\n",
      "  1.6639282  -1.8220382   2.1154168  -1.2516415  -2.8340168   0.44802064\n",
      "  5.0285215  -0.07429399 -0.2509875  -3.8180683 ]\n"
     ]
    }
   ],
   "source": [
    "print(embed_model_cbow['kral']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e9f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0dc653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'two'),\n",
       " (0.0, 'nine'),\n",
       " (0.0, 'three'),\n",
       " (0.0, 'r'),\n",
       " (0.0, 've'),\n",
       " (0.0, 'four'),\n",
       " (0.0, 'dojosunu'),\n",
       " (0.0, 'sithtmdetails'),\n",
       " (0.0, 'havayolar'),\n",
       " (0.0, 'tutanaklarda')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model_cbow.get_nearest_neighbors(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1deecc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 247M words\n",
      "Number of words:  443672\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   74852 lr:  0.000000 avg.loss:  0.123364 ETA:   0h 0m 0s  0.0% words/sec/thread:   67176 lr:  0.049988 avg.loss:  2.561009 ETA:   1h42m20s  4.0% words/sec/thread:   77278 lr:  0.047992 avg.loss:  1.165188 ETA:   1h25m25s  4.4% words/sec/thread:   77169 lr:  0.047798 avg.loss:  1.151303 ETA:   1h25m11s  6.6% words/sec/thread:   79455 lr:  0.046708 avg.loss:  0.937080 ETA:   1h20m51s 12.9% words/sec/thread:   81644 lr:  0.043557 avg.loss:  0.662723 ETA:   1h13m22s 13.8% words/sec/thread:   81735 lr:  0.043113 avg.loss:  0.644022 ETA:   1h12m32s 19.1% words/sec/thread:   82194 lr:  0.040473 avg.loss:  0.571332 ETA:   1h 7m43s 21.3% words/sec/thread:   82403 lr:  0.039348 avg.loss:  0.516128 ETA:   1h 5m40s 21.7% words/sec/thread:   82341 lr:  0.039163 avg.loss:  0.507160 ETA:   1h 5m25s 22.4% words/sec/thread:   82356 lr:  0.038788 avg.loss:  0.490504 ETA:   1h 4m46s 37.4% words/sec/thread:   83565 lr:  0.031303 avg.loss:  0.303571 ETA:   0h51m31s words/sec/thread:   83553 lr:  0.031223 avg.loss:  0.302326 ETA:   0h51m23s 37.9% words/sec/thread:   83537 lr:  0.031056 avg.loss:  0.299797 ETA:   0h51m 7s 43.0% words/sec/thread:   83506 lr:  0.028504 avg.loss:  0.265866 ETA:   0h46m56s0.263945 ETA:   0h46m41s 56.1% words/sec/thread:   82881 lr:  0.021972 avg.loss:  0.208965 ETA:   0h36m27s words/sec/thread:   81620 lr:  0.021176 avg.loss:  0.203660 ETA:   0h35m41s 57.7% words/sec/thread:   81526 lr:  0.021166 avg.loss:  0.203602 ETA:   0h35m42s 57.7% words/sec/thread:   81461 lr:  0.021159 avg.loss:  0.203559 ETA:   0h35m43s57.7% words/sec/thread:   81422 lr:  0.021153 avg.loss:  0.203517 ETA:   0h35m43s 57.7% words/sec/thread:   81360 lr:  0.021140 avg.loss:  0.203429 ETA:   0h35m44s 60.2% words/sec/thread:   79990 lr:  0.019904 avg.loss:  0.195799 ETA:   0h34m13s 61.6% words/sec/thread:   79360 lr:  0.019215 avg.loss:  0.191707 ETA:   0h33m18s 61.8% words/sec/thread:   79256 lr:  0.019077 avg.loss:  0.190868 ETA:   0h33m 6s 64.4% words/sec/thread:   78694 lr:  0.017816 avg.loss:  0.184068 ETA:   0h31m 8s 65.4% words/sec/thread:   78100 lr:  0.017293 avg.loss:  0.181262 ETA:   0h30m27s 65.5% words/sec/thread:   78080 lr:  0.017247 avg.loss:  0.181170 ETA:   0h30m22s 65.6% words/sec/thread:   78095 lr:  0.017205 avg.loss:  0.181104 ETA:   0h30m18s 66.2% words/sec/thread:   77824 lr:  0.016913 avg.loss:  0.179573 ETA:   0h29m53s 66.2% words/sec/thread:   77791 lr:  0.016904 avg.loss:  0.179525 ETA:   0h29m53s 66.2% words/sec/thread:   77736 lr:  0.016891 avg.loss:  0.179452 ETA:   0h29m53s 66.2% words/sec/thread:   77717 lr:  0.016882 avg.loss:  0.179407 ETA:   0h29m52s 66.3% words/sec/thread:   77629 lr:  0.016841 avg.loss:  0.179177 ETA:   0h29m50s 68.5% words/sec/thread:   77387 lr:  0.015740 avg.loss:  0.173839 ETA:   0h27m58s  77591 lr:  0.014129 avg.loss:  0.166983 ETA:   0h25m 2s 72.4% words/sec/thread:   77516 lr:  0.013821 avg.loss:  0.165718 ETA:   0h24m31s.165647 ETA:   0h24m31s 72.4% words/sec/thread:   77248 lr:  0.013788 avg.loss:  0.165577 ETA:   0h24m33s 72.7% words/sec/thread:   77141 lr:  0.013671 avg.loss:  0.165067 ETA:   0h24m22s 72.8% words/sec/thread:   77079 lr:  0.013602 avg.loss:  0.164769 ETA:   0h24m16s 72.8% words/sec/thread:   77058 lr:  0.013600 avg.loss:  0.164761 ETA:   0h24m16s75.3% words/sec/thread:   76703 lr:  0.012338 avg.loss:  0.159679 ETA:   0h22m 7s 75.6% words/sec/thread:   76643 lr:  0.012180 avg.loss:  0.159061 ETA:   0h21m51s 75.7% words/sec/thread:   76592 lr:  0.012169 avg.loss:  0.159016 ETA:   0h21m51s 75.7% words/sec/thread:   76549 lr:  0.012145 avg.loss:  0.158932 ETA:   0h21m49s 77.0% words/sec/thread:   76300 lr:  0.011500 avg.loss:  0.156481 ETA:   0h20m43s 77.3% words/sec/thread:   76283 lr:  0.011345 avg.loss:  0.155904 ETA:   0h20m27s 81.7% words/sec/thread:   76215 lr:  0.009172 avg.loss:  0.148149 ETA:   0h16m33s 82.5% words/sec/thread:   76150 lr:  0.008758 avg.loss:  0.146749 ETA:   0h15m49s 82.5% words/sec/thread:   76149 lr:  0.008747 avg.loss:  0.146707 ETA:   0h15m47s 83.1% words/sec/thread:   76128 lr:  0.008460 avg.loss:  0.145722 ETA:   0h15m17s 83.3% words/sec/thread:   76119 lr:  0.008366 avg.loss:  0.145417 ETA:   0h15m 6s0.144110 ETA:   0h14m23s 84.9% words/sec/thread:   75927 lr:  0.007563 avg.loss:  0.142923 ETA:   0h13m42s13m20sm47s 90.7% words/sec/thread:   76232 lr:  0.004661 avg.loss:  0.134826 ETA:   0h 8m24s 92.9% words/sec/thread:   76451 lr:  0.003532 avg.loss:  0.132091 ETA:   0h 6m21s 93.3% words/sec/thread:   76386 lr:  0.003326 avg.loss:  0.131541 ETA:   0h 5m59s 93.4% words/sec/thread:   76334 lr:  0.003315 avg.loss:  0.131514 ETA:   0h 5m58s 93.4% words/sec/thread:   76305 lr:  0.003312 avg.loss:  0.131504 ETA:   0h 5m58s 93.5% words/sec/thread:   76236 lr:  0.003265 avg.loss:  0.131379 ETA:   0h 5m53s lr:  0.002878 avg.loss:  0.130342 ETA:   0h 5m13s 5m12s 96.1% words/sec/thread:   74954 lr:  0.001928 avg.loss:  0.127958 ETA:   0h 3m32s 97.4% words/sec/thread:   74896 lr:  0.001308 avg.loss:  0.126430 ETA:   0h 2m24s\n"
     ]
    }
   ],
   "source": [
    "embed_model_skipgram = fasttext.train_unsupervised('dataset/data_embed', model='skipgram')\n",
    "embed_model_skipgram.save_model(SKIPGRAM_EMBED)\n",
    "embed_model_skipgram = fasttext.load_model(SKIPGRAM_EMBED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8060b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_skipgram = fasttext.load_model(SKIPGRAM_EMBED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6600ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14061163  0.21152861  0.37297234  0.17459579 -0.06302437 -0.23896378\n",
      " -0.0406476   0.48994002  0.85156524  0.24002695  0.17524059  0.27344623\n",
      "  0.28669873 -0.20847699  0.24135225 -0.52514803  0.16876692  0.05644416\n",
      " -0.7636112   0.57508785 -0.1068361  -0.51401365  0.28645584  0.04247218\n",
      " -0.23114674  0.05552669  0.53369427  0.6509493  -0.43459892 -0.22358531\n",
      " -0.00744076  0.33292818 -0.0874656   0.09704663  0.02884606 -0.5719166\n",
      "  0.09101292  0.2132607   0.3231337  -0.07480907  0.0565987   0.25604635\n",
      "  0.5738702   0.24749093  0.47816133  0.512537    0.7872196   0.45064402\n",
      " -0.05651958  0.6161764   0.16024846  0.52799463  0.28019077  0.85644996\n",
      "  0.56254166 -0.27865806  0.35512173 -0.15564233  0.12851554 -0.04819189\n",
      "  0.49310368  0.56622326 -0.30021083 -0.26640487  0.88466156 -0.04250515\n",
      " -0.12148838  0.28936973 -0.2367553   0.07663409 -0.54772973  0.0713184\n",
      "  0.27757034 -0.89804256  0.15931012  0.34308848  0.30547467 -0.09906186\n",
      "  0.21058516 -0.29232493  0.0034294   0.4890303  -0.24436696  0.00555835\n",
      " -0.39094627 -0.64635265  0.07750459 -0.10007867  0.3917649   0.23357414\n",
      " -0.25625584 -0.3657456  -0.06075604  0.00414856 -0.55685645  0.082157\n",
      "  0.3377067  -0.3713417  -0.12459658 -0.10524766]\n"
     ]
    }
   ],
   "source": [
    "print(embed_model_skipgram['kral']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12384c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'two'),\n",
       " (0.0, 'nine'),\n",
       " (0.0, 'three'),\n",
       " (0.0, 'r'),\n",
       " (0.0, 've'),\n",
       " (0.0, 'four'),\n",
       " (0.0, 'dojosunu'),\n",
       " (0.0, 'sithtmdetails'),\n",
       " (0.0, 'havayolar'),\n",
       " (0.0, 'tutanaklarda')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model_skipgram.get_nearest_neighbors(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c313920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7531418204307556, 'samsung'),\n",
       " (0.7077250480651855, 'redmi'),\n",
       " (0.6996424198150635, 'axy'),\n",
       " (0.6976189613342285, 'xperia'),\n",
       " (0.6925432682037354, 'duos'),\n",
       " (0.6889880895614624, 'phablet'),\n",
       " (0.6831598877906799, 'touchwiz'),\n",
       " (0.6829336285591125, 'meizu'),\n",
       " (0.6817553043365479, 'telefoto'),\n",
       " (0.6693254113197327, 'galax')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model_skipgram.get_analogies(\"iphone\", \"apple\", \"galaxy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107a06d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer:Anology I find was: iphone, apple, galaxy  and it outputted samsung which is reasonable. I am not %100 sure about how they are calculated but it probably compares first two word's embeddings, then based on in which way they are correlated, projects third word vector into that dimension and finds closest (in terms of cosine similarity) word embedding vector in that dimension.\n"
     ]
    }
   ],
   "source": [
    "#### Inline Question 2: Find an example of an analogy that holds, using the `get_analogies` function. Explain the analogy and also how the analogies are calculated.\n",
    "\n",
    "print(\"Your answer:Anology I find was: iphone, apple, galaxy  and it outputted samsung which is reasonable. I am not %100 sure about how they are calculated but it probably compares first two word's embeddings, then based on in which way they are correlated, projects third word vector into that dimension and finds closest (in terms of cosine similarity) word embedding vector in that dimension.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d5239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f4611c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the seeds for reproducibility\n",
    "SEED = 542\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "579feeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ee5551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses a file in the Universal Dependencies (UD) annotation style and returns a list of all the sentences in the file.\n",
    "    Note: The data files you need in this part of the assignemnt are stored under the dataset/ directory. You can open the\n",
    "    files to have a better understanding of the format. If you want to learn more about the POS tags, you can visit the\n",
    "    Universal Dependencies website: https://universaldependencies.org/tr/pos/index.html\n",
    "\n",
    "    The output should be a list of tuples, where each tuple represents a sentence and contains (word, POS tag) pairs for each\n",
    "    word in the sentence. For example, the following sentence:\n",
    "\n",
    "    \"The quick brown fox jumps over the lazy dog.\"\n",
    "    should be represented as:\n",
    "    [(\"The\", \"DET\"), (\"quick\", \"ADJ\"), (\"brown\", \"ADJ\"), (\"fox\", \"NOUN\"), (\"jumps\", \"VERB\"), (\"over\", \"ADP\"), (\"the\", \"DET\"), (\"lazy\", \"ADJ\"), (\"dog\", \"NOUN\"), (\".\", \"PUNCT\")]\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): The path to the file to be parsed.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of tuples, where each tuple represents a sentence and contains (word, POS tag) pairs for each word in the sentence.\n",
    "    \"\"\"\n",
    "    # *****START OF YOUR CODE*****\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            \n",
    "            elif not line:\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                columns = line.split(\"\\t\")\n",
    "                word, pos_tag = columns[1], columns[3]\n",
    "                sentence.append((word, pos_tag))\n",
    "\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # *****END OF YOUR CODE*****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ba0ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Adeta', 'ADV'),\n",
       " ('kendimden', 'PRON'),\n",
       " ('geçmiş', 'VERB'),\n",
       " ('bir', 'DET'),\n",
       " ('haldeyim', '_'),\n",
       " ('halde', 'NOUN'),\n",
       " ('yim', 'AUX'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posTags = parse_file(\"dataset/train.conllu\")\n",
    "posTags[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1a1ec81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('kendimden', 'PRON')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7803"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(posTags[1][1])\n",
    "len(posTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07fe96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb9713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data: List[List[Tuple[str, str]]]) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Builds a vocabulary of words and part-of-speech (POS) tags based on the input data. Don't forget to add special tokens (e.g. <PAD>, <UNK>, etc.)\n",
    "\n",
    "    Args:\n",
    "    data (List[List[Tuple[str, str]]]): A list of sentences, where each sentence is represented as a list of (word, POS tag) tuples.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[Dict[str, int], Dict[str, int]]: A tuple containing two dictionaries. The first dictionary maps words to their index in the vocabulary, and the second dictionary maps POS tags to their index in the vocabulary.\n",
    "    \"\"\"  \n",
    "    # *****START OF YOUR CODE*****\n",
    " \n",
    "    Dict1 = {}\n",
    "    Dict2 = {}\n",
    "    Dict1[\"<PAD>\"] = 0\n",
    "    Dict1[\"<UNK>\"] = 1\n",
    "    Dict2[\"<PAD>\"] = 0\n",
    "    Dict2[\"<UNK>\"] = 1\n",
    "    currentIndexWord = 2\n",
    "\n",
    "    currentIndexPos = 2\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j][0] not in Dict1.keys():\n",
    "                Dict1[data[i][j][0]] = currentIndexWord\n",
    "                currentIndexWord += 1\n",
    "                currentPos = '<' + data[i][j][1] + '>'\n",
    "\n",
    "                if currentPos not in Dict2.keys():\n",
    "                        Dict2['<' + data[i][j][1] + '>'] = currentIndexPos\n",
    "                        currentIndexPos += 1\n",
    "\n",
    "\n",
    "                    \n",
    "    return (Dict1, Dict2)\n",
    "    \n",
    "    # *****END OF YOUR CODE*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1778a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "data = posTags\n",
    "a = build_vocab(data)\n",
    "wordDict = a[0]\n",
    "posDict = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9de1a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('1936', 'NUM'), ('yılındayız', '_'), ('yılında', 'NOUN'), ('yız', 'AUX'), ('.', 'PUNCT')], [('Adeta', 'ADV'), ('kendimden', 'PRON'), ('geçmiş', 'VERB'), ('bir', 'DET'), ('haldeyim', '_'), ('halde', 'NOUN'), ('yim', 'AUX'), ('.', 'PUNCT')], [('O', 'PRON'), ('nasıl', 'ADV'), ('derse', 'VERB'), ('desin', 'VERB'), ('uğraştığı', 'VERB'), ('sanatın', 'NOUN'), ('kendisine', 'PRON'), ('emanet', 'NOUN'), ('olduğunu', 'VERB'), ('söyleyen', 'VERB'), ('üstadları', 'NOUN'), ('vardı', '_'), ('var', 'NOUN'), ('dı', 'AUX'), ('.', 'PUNCT')], [('Ahmed', 'PROPN'), ('Rasim', 'PROPN'), (',', 'PUNCT'), (\"Büyükada'ya\", 'PROPN'), ('gidip', 'VERB'), ('birkaç', 'DET'), ('gün', 'NOUN'), ('kalmayı', 'VERB'), ('tasarlamıştı', '_'), ('tasarlamış', 'VERB'), ('tı', 'AUX'), ('.', 'PUNCT')], [('Rüzgâr', 'NOUN'), ('yine', 'ADV'), ('güçlü', 'ADV'), ('esiyordu', '_'), ('esiyor', 'VERB'), ('du', 'AUX'), ('.', 'PUNCT')], [('Öte', 'NOUN'), ('yandan', 'NOUN'), ('Sarı', 'ADJ'), ('-', 'PUNCT'), ('Lacivertliler', 'NOUN'), (',', 'PUNCT'), ('yarın', 'NOUN'), ('Samandıra', 'PROPN'), (\"Tesisleri'nde\", 'NOUN'), ('Türk', 'NOUN'), ('Telekom', 'PROPN'), ('Lig', 'PROPN'), ('A', 'PROPN'), ('takımlarından', 'NOUN'), (\"Kocaelispor'la\", 'PROPN'), ('saat', 'NOUN'), (\"19.30'da\", 'NOUN'), ('bir', 'DET'), ('hazırlık', 'NOUN'), ('maçı', 'NOUN'), ('yapacak', 'VERB'), ('.', 'PUNCT')], [('Peki', 'ADV'), ('kim', 'PRON'), ('bu', 'DET'), ('küçük', 'ADJ'), ('ve', 'CCONJ'), ('basit', 'ADJ'), ('sebepleri', 'NOUN'), ('devleştirerek', 'VERB'), ('aramıza', 'NOUN'), ('sokup', 'VERB'), ('duruyor', 'AUX'), ('?', 'PUNCT')], [('Meşrutiyetin', 'PROPN'), ('ilanından', 'NOUN'), ('önceki', 'ADJ'), ('siyasi', 'ADJ'), ('faaliyetlere', 'NOUN'), ('katıldı', 'VERB'), ('.', 'PUNCT')], [('-', 'PUNCT'), ('Öger', 'PROPN'), ('Prodüksiyon', 'PROPN'), ('.', 'PUNCT')], [(\"'\", 'PUNCT'), ('Yalnız', 'ADV'), (',', 'PUNCT'), ('neden', 'ADV'), ('yaşamak', 'VERB'), ('ıstırap', 'NOUN'), ('verici', 'ADJ'), ('bir', 'DET'), ('şey', 'NOUN'), ('?', 'PUNCT')], [('1978', 'NUM'), ('yılında', 'NOUN'), (',', 'PUNCT'), ('Unesco', 'PROPN'), ('Yürütme', 'VERB'), (\"Kurulu'na\", 'NOUN'), (',', 'PUNCT'), (\"Türkiye'yi\", 'PROPN'), ('temsil', 'NOUN'), ('edecek', 'VERB'), ('üye', 'NOUN'), ('olarak', 'AUX'), ('seçilmiştim', '_'), ('seçilmiş', 'VERB'), ('tim', 'AUX'), ('.', 'PUNCT')], [('Yatağan', 'PROPN'), (',', 'PUNCT'), ('Milas', 'PROPN'), ('ve', 'CCONJ'), ('Akılcılık', 'PROPN'), ('...', 'PUNCT')], [('\"', 'PUNCT'), ('Yeni', 'ADV'), ('emekli', 'ADJ'), ('olmuş', 'VERB'), ('general', 'ADJ'), ('bir', 'DET'), ('dostum', 'NOUN'), (',', 'PUNCT'), ('taşındığı', 'VERB'), ('95', 'NUM'), ('metrekarelik', 'ADJ'), ('evinde', 'NOUN'), (',', 'PUNCT'), ('aldığı', 'VERB'), ('plaketleri', 'NOUN'), ('asacak', 'VERB'), ('duvar', 'NOUN'), ('bulamadığı', 'VERB'), ('gibi', 'ADP'), ('bunları', 'PRON'), ('yerleştirdiği', 'VERB'), ('sandıkları', 'NOUN'), ('koyacak', 'VERB'), ('yer', 'NOUN'), ('olmadığından', 'VERB'), ('yakındı', 'VERB'), (',', 'PUNCT'), (\"'\", 'PUNCT'), ('Ne', 'PRON'), ('yapayım', 'VERB'), ('?', 'PUNCT'), (\"'\", 'PUNCT'), ('dedi', 'VERB'), ('.', 'PUNCT'), ('\"', 'PUNCT')], [('Bu', 'DET'), ('işe', 'NOUN'), ('bir', 'DET'), ('çözüm', 'NOUN'), ('bulacağınızı', 'VERB'), ('ümit', 'NOUN'), ('ediyor', 'VERB'), ('saygılar', 'NOUN'), ('sunuyorum', 'VERB'), ('.', 'PUNCT')], [('1966', 'NUM'), ('yılında', 'NOUN'), ('Bafa', 'PROPN'), ('gölünün', 'NOUN'), ('kuzeyinde', 'NOUN'), ('yer', 'NOUN'), ('alan', 'VERB'), ('Kayalık', 'PROPN'), ('Beşparmak', 'PROPN'), ('dağlarına', 'NOUN'), ('tırmanıyorduk', '_'), ('tırmanıyor', 'VERB'), ('duk', 'AUX'), ('.', 'PUNCT')], [('Ama', 'CCONJ'), ('beni', 'PRON'), ('basketbol', 'NOUN'), ('takımına', 'NOUN'), ('almadılar', 'VERB'), ('.', 'PUNCT')], [('Bundan', 'PRON'), ('sonra', 'ADV'), ('\"', 'PUNCT'), ('çağdaş', 'ADJ'), ('olimpiyatlar', 'NOUN'), ('\"', 'PUNCT'), ('adıyla', 'NOUN'), ('anıldı', 'VERB'), ('.', 'PUNCT')], [('\"', 'PUNCT'), ('Müjdeler', 'NOUN'), ('var', 'NOUN'), ('yurdumun', 'NOUN'), ('toprağına', 'NOUN'), ('taşına', 'NOUN'), (',', 'PUNCT')], [('Onun', 'PRON'), ('için', 'ADP'), ('yol', 'NOUN'), ('arkadaşlarımızı', 'NOUN'), ('titizlikle', 'NOUN'), ('seçer', 'VERB'), (',', 'PUNCT'), ('kendilerini', 'PRON'), ('iyice', 'ADV'), ('sınarız', 'VERB'), ('.', 'PUNCT')], [('Savcı', 'NOUN'), (',', 'PUNCT'), ('petrol', 'NOUN'), ('tankerinin', 'NOUN'), ('Hintli', 'PROPN'), ('kaptanının', 'NOUN'), ('da', 'PART'), ('olayda', 'NOUN'), ('bir', 'DET'), ('ihmali', 'NOUN'), ('bulunup', 'VERB'), ('bulunmadığını', 'VERB'), ('araştırıyor', 'VERB'), ('.', 'PUNCT')], [('Kahvaltıya', 'NOUN'), ('kadar', 'ADP'), ('2', 'NUM'), ('saat', 'NOUN'), ('çalışırım', 'VERB'), ('.', 'PUNCT')], [('\"', 'PUNCT'), ('Neden', 'ADV'), ('?', 'PUNCT'), ('\"', 'PUNCT'), ('diye', 'ADP'), ('sordum', 'VERB'), ('.', 'PUNCT')], [('Bu', 'DET'), ('korkular', 'NOUN'), (',', 'PUNCT'), ('hayatımızın', 'NOUN'), ('çeşitli', 'ADJ'), ('dönemlerinde', 'NOUN'), ('değişiklikler', 'NOUN'), ('gösterebilir', 'VERB'), ('.', 'PUNCT')], [('Örneğin', 'ADV'), (',', 'PUNCT'), ('bu', 'DET'), ('alanda', 'NOUN'), ('Mars', 'PROPN'), (',', 'PUNCT'), ('bizi', 'PRON'), ('aşırı', 'ADV'), ('sahip', 'NOUN'), ('olmacı', 'ADJ'), ('biri', 'PRON'), ('yaparken', '_'), ('yapar', 'VERB'), ('ken', 'AUX'), (',', 'PUNCT'), ('miras', 'NOUN'), ('konusunda', 'NOUN'), ('engeller', 'NOUN'), ('çıkarabilir', 'VERB'), ('.', 'PUNCT')], [('Tapınakta', 'NOUN'), ('panik', 'NOUN'), ('var', 'NOUN')], [('Arabalarımıza', 'NOUN'), ('kartondan', 'NOUN'), ('garaj', 'NOUN'), ('yaparız', 'VERB'), ('.', 'PUNCT')], [('İçindeki', '_'), ('İçinde', 'NOUN'), ('ki', 'PART'), ('isimler', 'NOUN'), ('ve', 'CCONJ'), ('telefon', 'NOUN'), ('numaralarından', 'NOUN'), ('yola', 'NOUN'), ('çıkarak', 'VERB'), ('başka', 'ADJ'), ('operasyonlar', 'NOUN'), ('yaptık', 'VERB'), (',', 'PUNCT'), ('ama', 'CCONJ'), ('bunlar', 'PRON'), ('ayrı', 'ADJ'), ('bir', 'DET'), ('öykü', 'NOUN'), ('.', 'PUNCT'), ('\"', 'PUNCT')], [('İkisi', 'NUM'), ('de', 'PART'), (\"Türkiye'nin\", 'PROPN'), ('sevdalısı', 'NOUN'), ('.', 'PUNCT')], [('Tüm', 'DET'), ('dostlara', 'NOUN'), ('haber', 'NOUN'), ('ulaştıramadım', 'VERB'), (',', 'PUNCT'), ('ama', 'CCONJ'), ('kalan', 'VERB'), ('dostlar', 'NOUN'), ('her', 'DET'), ('şeyi', 'NOUN'), ('halletti', 'VERB'), ('.', 'PUNCT')], [('Her', 'DET'), ('istediklerini', 'VERB'), ('verirseniz', '_'), ('verir', 'VERB'), ('seniz', 'AUX'), ('kıymet', 'NOUN'), ('bilmezler', 'VERB'), (',', 'PUNCT'), ('üstelik', 'ADV'), ('hiçbir', 'DET'), ('şeyden', 'NOUN'), ('zevk', 'NOUN'), ('almaz', 'VERB'), ('olurlar', 'AUX'), ('.', 'PUNCT')], [('ABD', 'PROPN'), ('Başkanı', 'NOUN'), ('George', 'PROPN'), ('Bush', 'PROPN'), (',', 'PUNCT'), (\"Irak'taki\", '_'), (\"Irak'ta\", 'PROPN'), ('ki', 'PART'), ('Amerikan', 'PROPN'), ('birliklerinin', 'NOUN'), ('omuzlarındaki', '_'), ('omuzlarında', 'NOUN'), ('ki', 'PART'), ('yükün', 'NOUN'), (',', 'PUNCT'), ('sonbaharda', 'NOUN'), ('müttefiklerin', 'NOUN'), ('gelişiyle', 'VERB'), ('hafifleyeceğini', 'VERB'), ('söyledi', 'VERB'), ('.', 'PUNCT')], [('\"', 'PUNCT'), ('Bunu', 'PRON'), ('da', 'PART'), ('mı', 'AUX'), ('o', 'PRON'), ('yapmış', 'VERB'), ('?', 'PUNCT'), ('\"', 'PUNCT')], [('Yarım', 'ADJ'), ('greyfurt', 'NOUN'), ('günlük', 'ADJ'), ('C', 'NOUN'), ('vitamini', 'NOUN'), ('ihtiyacının', 'NOUN'), ('yüzde', 'NUM'), ('altmışını', 'NUM'), ('sağlar', 'VERB'), ('.', 'PUNCT')], [('1', 'NUM'), ('yemek', 'NOUN'), ('kaşığı', 'NOUN'), ('zeytinyağı', 'NOUN')], [('Yan', 'ADJ'), ('tarafında', 'NOUN'), ('da', 'PART'), ('kocaman', 'ADJ'), ('bir', 'DET'), ('kavanoz', 'NOUN'), ('.', 'PUNCT')], [('O', 'DET'), ('hanımı', 'NOUN'), ('asistan', 'NOUN'), ('yaptılar', 'VERB'), ('.', 'PUNCT')], [('Mini', 'ADJ'), ('dizüstünde', 'NOUN'), ('3N', 'NOUN'), ('dopingi', 'NOUN')], [('Ama', 'CCONJ'), ('hayatta', 'NOUN'), ('her', 'DET'), ('şey', 'NOUN'), ('bizim', 'PRON'), ('istediğimiz', 'VERB'), ('gibi', 'ADP'), ('olmuyor', 'VERB'), ('.', 'PUNCT')], [('Öyleyse', 'ADV'), (',', 'PUNCT'), ('ben', 'PRON'), ('bir', 'DET'), ('İspanyol', 'PROPN'), ('olduğum', 'AUX'), ('kadar', 'ADP'), ('dünyalıyım', '_'), ('dünyalı', 'NOUN'), ('yım', 'AUX'), ('da', 'PART'), ('.', 'PUNCT')], [('Bu', 'DET'), ('yaş', 'NOUN'), ('diliminin', 'NOUN'), ('en', 'ADV'), ('az', 'ADV'), ('çalışanları', 'VERB'), ('ise', 'PART'), ('Slovakya', 'PROPN'), (',', 'PUNCT'), ('Belçika', 'PROPN'), ('ve', 'CCONJ'), (\"Fransa'da\", 'PROPN'), ('.', 'PUNCT')], [('Bunu', 'PRON'), ('umuyoruz', 'VERB'), ('.', 'PUNCT')], [('Bu', 'DET'), ('kararla', 'NOUN'), ('polise', 'NOUN'), ('ve', 'CCONJ'), ('savcılıklara', 'NOUN'), ('bu', 'DET'), ('yönde', 'NOUN'), ('yapılan', 'VERB'), ('şikâyetlerin', 'NOUN'), ('de', 'PART'), ('azalacağı', 'VERB'), ('belirtildi', 'VERB'), ('.', 'PUNCT')], [('Moby', 'PROPN'), (\"Dick'e\", 'PROPN'), ('aldığım', 'VERB'), ('sarı', 'ADJ'), ('boya', 'NOUN'), ('inceltmek', 'VERB'), ('için', 'ADP'), ('ne', 'CCONJ'), ('gaz', 'NOUN'), (',', 'PUNCT'), ('ne', 'CCONJ'), ('benzin', 'NOUN'), (',', 'PUNCT'), ('hiçbir', 'DET'), ('şey', 'NOUN'), ('kabul', 'NOUN'), ('etmiyordu', '_'), ('etmiyor', 'VERB'), ('du', 'AUX'), ('.', 'PUNCT')], [('Telsiz', 'NOUN'), (',', 'PUNCT'), ('sürekli', 'ADV'), ('olarak', 'AUX'), ('işliyor', 'VERB'), (',', 'PUNCT'), ('tamamlayıcı', 'ADJ'), ('haberler', 'NOUN'), ('geliyor', 'VERB'), (',', 'PUNCT'), ('buyruklar', 'NOUN'), ('yerine', 'NOUN'), ('ulaşıyordu', '_'), ('ulaşıyor', 'VERB'), ('du', 'AUX'), ('.', 'PUNCT')], [('1', 'NUM'), ('kutu', 'NOUN'), ('ançüez', 'NOUN')], [('Dünyaca', 'ADV'), ('ünlü', 'ADJ'), ('obuacı', 'NOUN'), ('oturup', 'VERB'), ('bir', 'DET'), ('süre', 'NOUN'), ('dinledi', 'VERB'), (',', 'PUNCT'), ('sonra', 'ADV'), ('solisti', 'NOUN'), ('tanımak', 'VERB'), ('istediğini', 'VERB'), ('söyledi', 'VERB'), ('.', 'PUNCT')], [('O', 'PRON'), (',', 'PUNCT'), ('öncelikle', 'ADV'), ('çok', 'ADV'), ('büyük', 'ADJ'), ('bir', 'DET'), ('asker', 'NOUN'), ('ve', 'CCONJ'), ('komutandır', 'NOUN'), ('.', 'PUNCT')], [('Çocuklardan', 'NOUN'), ('biri', 'PRON'), (',', 'PUNCT')], [('Köylülerin', 'NOUN'), ('çoğu', 'PRON'), ('evlere', 'NOUN'), ('girmemişti', '_'), ('girmemiş', 'VERB'), ('ti', 'AUX'), (';', 'PUNCT'), ('çünkü', 'SCONJ'), ('söylediklerine', 'VERB'), ('göre', 'ADP'), ('ısınamıyorlardı', '_'), ('ısınamıyorlar', 'VERB'), ('dı', 'AUX'), ('.', 'PUNCT')], [('Sesleri', 'NOUN'), ('duyan', 'VERB'), (',', 'PUNCT'), ('şirkete', 'NOUN'), ('yeni', 'ADV'), ('girmiş', 'VERB'), ('kaptan', 'NOUN'), (',', 'PUNCT'), ('şaşkın', 'ADJ'), ('ve', 'CCONJ'), ('ürkek', 'ADJ'), ('bir', 'DET'), ('ifadeyle', 'NOUN'), ('boxerını', 'PROPN'), ('çekiştirerek', 'VERB'), ('tuvaletten', 'NOUN'), ('fırladı', 'VERB'), ('.', 'PUNCT')], [('Alelacele', 'ADV'), ('el', 'NOUN'), ('edip', 'VERB'), ('durdurdum', 'VERB'), ('ve', 'CCONJ'), ('bindik', 'VERB'), ('.', 'PUNCT')], [('Sarı', 'ADJ'), (',', 'PUNCT'), ('beyaz', 'ADJ'), (',', 'PUNCT'), ('pembe', 'ADJ'), ('renkli', 'ADJ'), ('cinsleri', 'NOUN'), ('içinde', 'NOUN'), ('en', 'ADV'), ('çok', 'ADV'), ('beyazı', 'NOUN'), ('sevilir', 'VERB'), ('.', 'PUNCT')], [('Dünyada', 'NOUN'), ('uluslararası', 'ADJ'), ('duruma', 'NOUN'), ('göre', 'ADP'), ('böyle', 'ADJ'), ('bir', 'DET'), ('mücadelenin', 'NOUN'), ('gerektirdiği', 'VERB'), ('manevi', 'ADJ'), ('unsurlara', 'NOUN'), ('sahip', 'NOUN'), ('olmayan', 'VERB'), ('kişiler', 'NOUN'), ('ve', 'CCONJ'), ('bu', 'DET'), ('nitelikte', 'NOUN'), ('kişilerden', 'NOUN'), ('oluşan', 'VERB'), ('toplumlara', 'NOUN'), ('hayat', 'NOUN'), ('ve', 'CCONJ'), ('bağımsızlık', 'NOUN'), ('yoktur', '_'), ('yok', 'NOUN'), ('tur', 'AUX'), ('.', 'PUNCT')], [('Ancak', 'CCONJ'), ('\"', 'PUNCT'), ('pet', 'PROPN'), ('therapist', 'PROPN'), ('\"', 'PUNCT'), ('i', 'PART'), ('size', 'PRON'), ('tanıtmadan', 'VERB'), ('geçemeyeceğim', 'VERB'), ('.', 'PUNCT')], [(\"Kadıköy'de\", 'PROPN'), (\"İstanbul'un\", 'PROPN'), ('Musevi', 'PROPN'), ('gençleri', 'NOUN'), (',', 'PUNCT'), ('Bobi', 'PROPN'), ('takma', 'ADJ'), ('adıyla', 'NOUN'), ('sahaya', 'NOUN'), ('çıkan', 'VERB'), ('ilk', 'ADJ'), ('Türk', 'PROPN'), ('futbolcusu', 'NOUN'), ('Fuat', 'PROPN'), ('Hüsnü', 'PROPN'), (',', 'PUNCT'), ('Büyük', 'ADJ'), ('Hasan', 'PROPN'), ('ve', 'CCONJ'), ('Dalaklı', 'PROPN'), ('Hüseyin', 'PROPN'), ('gibi', 'ADP'), ('isimler', 'NOUN'), ('de', 'PART'), ('forma', 'NOUN'), ('giydiler', 'VERB'), ('.', 'PUNCT')], [('İsrailli', 'PROPN'), ('yetkililerin', 'NOUN'), ('daha', 'ADV'), ('önce', 'ADV'), ('yaptıkları', 'VERB'), ('açıklamalarda', 'NOUN'), (',', 'PUNCT'), ('sınırın', 'NOUN'), ('İsrail', 'PROPN'), ('tarafına', 'NOUN'), ('gönderilen', 'VERB'), ('bazı', 'DET'), ('füzelerin', 'NOUN'), ('Suriye', 'PROPN'), ('tarafından', 'NOUN'), ('tahsis', 'NOUN'), ('edildiği', 'VERB'), ('ileri', 'ADV'), ('sürülürken', '_'), ('sürülür', 'VERB'), ('ken', 'AUX'), (',', 'PUNCT'), ('İsrail', 'PROPN'), ('Başbakanı', 'NOUN'), ('Ehud', 'PROPN'), (\"Olmert'in\", 'PROPN'), (',', 'PUNCT'), ('\"', 'PUNCT'), (\"Hizbullah'ı\", 'PROPN'), ('destekliyor', 'VERB'), ('\"', 'PUNCT'), ('diyerek', 'VERB'), (\"İran'ı\", 'PROPN'), ('da', 'PART'), ('suçlaması', 'VERB'), (',', 'PUNCT'), ('sona', 'NOUN'), ('erdirilmesi', 'VERB'), ('beklenen', 'VERB'), ('sorunun', 'NOUN'), ('daha', 'ADV'), ('büyük', 'ADJ'), ('bir', 'DET'), ('coğrafyaya', 'NOUN'), ('yayılabileceği', 'VERB'), ('kaygısını', 'NOUN'), ('uyandırıyor', 'VERB'), ('.', 'PUNCT')], [('Ne', 'PRON'), ('kadar', 'ADP'), ('düşünürsem', '_'), ('düşünür', 'VERB'), ('sem', 'AUX'), ('düşüneyim', 'VERB'), (',', 'PUNCT'), ('televizyonda', 'NOUN'), ('izlediklerimden', 'VERB'), ('başka', 'ADJ'), ('bir', 'DET'), ('fikir', 'NOUN'), ('gelmiyor', 'VERB'), ('aklıma', 'NOUN'), ('.', 'PUNCT')], [('Bence', 'PRON'), ('anne', 'NOUN'), ('babalar', 'NOUN'), ('da', 'PART'), ('tam', 'ADV'), ('olarak', 'AUX'), ('bilmiyordu', '_'), ('bilmiyor', 'VERB'), ('du', 'AUX'), ('niye', 'ADV'), ('olduğunu', 'VERB'), ('.', 'PUNCT')], [('Atkuyruğu', 'NOUN'), ('(', 'PUNCT'), ('zemberekotu', 'NOUN'), (')', 'PUNCT')], [(\"1925'in\", 'NUM'), ('ilk', 'ADJ'), ('yarısından', 'NOUN'), ('itibaren', 'ADP'), (',', 'PUNCT'), (\"Türkiye'de\", 'PROPN'), ('muhalefete', 'NOUN'), ('ve', 'CCONJ'), ('dolayısıyla', 'ADV'), ('siyasete', 'NOUN'), ('yaşama', 'VERB'), ('hakkı', 'NOUN'), ('tanınmamıştır', 'VERB'), ('.', 'PUNCT')], [('Ancak', 'CCONJ'), ('saldırıyı', 'NOUN'), ('henüz', 'ADV'), ('üstlenen', 'VERB'), ('olmadı', 'VERB'), ('.', 'PUNCT')], [('\"', 'PUNCT'), ('Grubumuz', 'NOUN'), (',', 'PUNCT'), ('190', 'NUM'), ('oyla', 'NOUN'), ('bir', 'DET'), ('Meclis', 'NOUN'), ('Başkanı', 'NOUN'), ('seçiminde', 'NOUN'), ('etkin', 'ADJ'), ('olamadığımızı', 'VERB'), ('düşündüğü', 'VERB'), ('anda', 'NOUN'), (',', 'PUNCT'), ('eğer', 'SCONJ'), (\"Meclis'in\", 'NOUN'), ('çalışmaya', 'VERB'), ('başlamasını', 'VERB'), ('sağlamak', 'VERB'), ('ve', 'CCONJ'), (\"Anayasa'nın\", 'NOUN'), (\"84'ncü\", 'NUM'), ('maddesinin', 'NOUN'), ('(', 'PUNCT'), ('bu', 'DET'), ('madde', 'NOUN'), ('başkanlık', 'NOUN'), ('divanında', 'NOUN'), ('partilerin', 'NOUN'), ('oyları', 'NOUN'), ('oranında', 'NOUN'), ('temsil', 'NOUN'), ('edilmesini', 'VERB'), ('öngörüyordu', '_'), ('öngörüyor', 'VERB'), ('du', 'AUX'), (')', 'PUNCT'), ('işlerliğinden', 'NOUN'), ('vazgeçmek', 'VERB'), ('ve', 'CCONJ'), ('1961', 'NUM'), ('yılından', 'NOUN'), ('beri', 'ADP'), ('uygulanmakta', 'VERB'), ('olan', 'AUX'), ('centilmenlik', 'NOUN'), ('anlaşmasından', 'NOUN'), ('da', 'PART'), ('vazgeçilmesine', 'VERB'), ('razı', 'ADJ'), ('olmak', 'VERB'), ('gibi', 'ADP'), ('üç', 'NUM'), ('ihtimalden', 'NOUN'), ('birini', 'NUM'), ('kabul', 'NOUN'), ('etseydik', '_'), ('etse', 'VERB'), ('ydik', 'AUX'), (',', 'PUNCT'), ('bugün', 'NOUN'), (\"Meclis'in\", 'NOUN'), ('belki', 'ADV'), ('bir', 'DET'), ('başkanı', 'NOUN'), ('olurdu', '_'), ('olur', 'VERB'), ('du', 'AUX'), ('.', 'PUNCT')], [('Dik', 'ADV'), ('dik', 'ADV'), ('yüzüne', 'NOUN'), ('baktı', 'VERB'), ('.', 'PUNCT')], [('Bütün', 'ADJ'), ('bir', 'DET'), ('günü', 'NOUN'), ('çalışmadan', 'VERB'), ('büyük', 'ADJ'), ('bir', 'DET'), ('sessizlik', 'NOUN'), ('içerisinde', 'NOUN'), ('geçirdik', '_'), ('geçir', 'VERB'), ('dik', 'AUX'), ('.', 'PUNCT')], [('O', 'DET'), ('zamanlar', 'NOUN'), (\"Kadifekale'de\", 'PROPN'), ('otururlarmış', '_'), ('otururlar', 'VERB'), ('mış', 'AUX'), ('.', 'PUNCT')], [('Fazla', 'NOUN'), ('sayıda', 'NOUN'), ('olmamakla', 'VERB'), ('birlikte', 'ADV'), ('bazı', 'DET'), ('kadınlar', 'NOUN'), ('da', 'PART'), ('orgazm', 'NOUN'), ('sırasında', 'NOUN'), ('boşalırlar', 'VERB'), ('.', 'PUNCT')], [(\"Türkiye'de\", 'PROPN'), ('hassasiyetlerimiz', 'NOUN'), ('var', 'NOUN'), ('.', 'PUNCT')], [('Sular', 'NOUN'), ('yaşıyor', 'VERB'), ('yanımda', 'NOUN')], [('Bu', 'DET'), ('stratejinin', 'NOUN'), ('ortaya', 'ADJ'), ('konulacağını', 'VERB'), (\"Hürriyet'te\", 'PROPN'), ('ilk', 'ADV'), ('ben', 'PRON'), ('yazmıştım', '_'), ('yazmış', 'VERB'), ('tım', 'AUX'), ('ve', 'CCONJ'), ('yazdıklarım', 'VERB'), ('da', 'PART'), ('olduğu', 'VERB'), ('gibi', 'ADP'), ('çıkmıştı', '_'), ('çıkmış', 'VERB'), ('tı', 'AUX'), ('.', 'PUNCT')], [('Benim', 'PRON'), ('için', 'ADP'), ('gerçek', 'ADJ'), ('anlamda', 'NOUN'), ('trajik', 'ADJ'), ('bir', 'DET'), ('olaya', 'NOUN'), ('dönüşmüş', 'VERB'), ('.', 'PUNCT')], [('-', 'PUNCT'), ('Üç', 'NUM'), ('demir', 'ADJ'), ('çubuk', 'NOUN'), ('bulup', 'VERB'), ('getirin', 'VERB'), (',', 'PUNCT'), ('dedi', 'VERB'), ('.', 'PUNCT')], [('Rehberimiz', 'NOUN'), ('yılların', 'NOUN'), ('verdiği', 'VERB'), ('ustalıkla', 'NOUN'), (',', 'PUNCT'), ('önünde', 'NOUN'), ('durduğumuz', 'VERB'), ('her', 'DET'), ('yapı', 'NOUN'), ('hakkında', 'NOUN'), ('bilgi', 'NOUN'), ('veriyor', 'VERB'), ('bize', 'PRON'), ('.', 'PUNCT')], [('Hiç', 'ADV'), ('ağrı', 'NOUN'), (',', 'PUNCT'), ('çürük', 'NOUN'), ('yok', 'NOUN'), (',', 'PUNCT')], [('Salt', 'ADV'), ('yargı', 'NOUN'), ('önüne', 'NOUN'), ('çıkarılmasın', 'VERB'), ('diye', 'ADP'), ('partisini', 'NOUN'), ('bağlayıp', 'VERB'), (',', 'PUNCT'), ('paketleyip', 'VERB'), ('Refah', 'PROPN'), (\"Partisi'ne\", 'NOUN'), ('rehin', 'NOUN'), ('bırakan', 'VERB'), ('Bayan', 'NOUN'), ('Çiller', 'PROPN'), ('ödülünü', 'NOUN'), ('alıyor', 'VERB'), ('.', 'PUNCT')], [('Panik', 'NOUN'), (',', 'PUNCT'), ('korku', 'NOUN'), (',', 'PUNCT'), ('acı', 'NOUN'), (',', 'PUNCT'), ('ürkek', 'ADJ'), ('ve', 'CCONJ'), ('donuk', 'ADJ'), ('bakışlar', 'VERB'), (',', 'PUNCT')], [('Yalnız', 'ADV'), ('kaldığında', 'VERB'), ('da', 'PART'), ('baktığından', 'VERB'), ('şüpheliyim', 'NOUN'), ('.', 'PUNCT')], [('Bayrama', 'VERB'), ('katılmak', 'VERB'), ('zorunludur', 'ADJ'), (';', 'PUNCT'), ('katılmayan', 'VERB'), (',', 'PUNCT'), ('köy', 'NOUN'), ('halkınca', 'NOUN'), ('dışlanır', 'VERB'), ('.', 'PUNCT')], [(\"Pamukkale'nin\", 'PROPN'), ('yanında', 'NOUN'), ('kule', 'NOUN'), ('gibi', 'ADP'), ('görünüşleri', 'NOUN'), ('ile', 'CCONJ'), ('Peri', 'PROPN'), ('Bacaları', 'NOUN'), ('karşılıyor', 'VERB'), ('ve', 'CCONJ'), ('sanki', 'ADV'), ('her', 'DET'), ('bir', 'DET'), ('baca', 'NOUN'), ('başındaki', '_'), ('başında', 'NOUN'), ('ki', 'PART'), ('komik', 'ADJ'), ('şapkası', 'NOUN'), ('ile', 'CCONJ'), ('bizlere', 'PRON'), ('gülümsüyor', 'VERB'), ('.', 'PUNCT')], [('Onu', 'PRON'), ('tutacak', 'VERB'), ('kimse', 'PRON'), ('yok', 'NOUN'), ('ki', 'PART'), ('!', 'PUNCT')], [(\"Japonya'nın\", 'PROPN'), ('dağarcığında', 'NOUN'), ('iki', 'NUM'), ('de', 'PART'), ('kış', 'NOUN'), ('olimpiyatı', 'NOUN'), ('ev', 'NOUN'), ('sahipliği', 'NOUN'), ('vardı', '_'), ('var', 'NOUN'), ('dı', 'AUX'), ('.', 'PUNCT')], [('Benim', 'PRON'), ('için', 'ADP'), ('de', 'PART'), ('takım', 'NOUN'), ('elbiselere', 'NOUN'), ('baktık', 'VERB'), ('.', 'PUNCT')], [('Oyak', 'PROPN'), ('Renault', 'PROPN'), ('Genel', 'ADJ'), ('Müdürü', 'NOUN'), ('Alain', 'PROPN'), ('Gabillet', 'PROPN'), ('ise', 'PART'), (',', 'PUNCT'), (\"Renault'nun\", 'PROPN'), ('üretiminin', 'NOUN'), ('geçen', 'ADJ'), ('yıl', 'NOUN'), ('yüzde', 'NUM'), (\"50'ye\", 'NUM'), ('yakın', 'ADJ'), ('oranda', 'NOUN'), ('artarak', 'VERB'), (',', 'PUNCT'), ('197', 'NUM'), ('bin', 'NUM'), ('353', 'NUM'), ('adede', 'NOUN'), ('çıktığını', 'VERB'), (',', 'PUNCT'), ('böylece', 'ADV'), ('rekor', 'NOUN'), ('kırdıklarını', 'VERB'), ('söyledi', 'VERB'), ('.', 'PUNCT')], [('Bu', 'DET'), ('korku', 'NOUN'), ('fırsatçılığı', 'NOUN'), ('sayesinde', 'NOUN'), ('dünyanın', 'NOUN'), ('en', 'ADV'), ('zengin', 'ADJ'), ('enerji', 'NOUN'), ('bölgeleri', 'NOUN'), ('işgal', 'NOUN'), ('edilmedi', 'VERB'), ('mi', 'AUX'), ('?', 'PUNCT')], [('On', 'NUM'), ('bir', 'NUM'), ('adım', 'NOUN'), ('saydı', 'VERB'), ('.', 'PUNCT')], [('Sağ', 'ADJ'), ('olanlar', 'AUX'), ('hele', 'ADV'), ('gençler', 'NOUN'), ('hastanın', 'NOUN'), ('halinden', 'NOUN'), ('anlamıyordu', '_'), ('anlamıyor', 'VERB'), ('du', 'AUX'), ('.', 'PUNCT')], [('Ve', 'CCONJ'), ('işte', 'ADV'), ('o', 'PRON'), (',', 'PUNCT'), ('beni', 'PRON'), ('kahreden', 'VERB'), (',', 'PUNCT'), ('somurtganlaştıran', 'VERB'), (',', 'PUNCT'), ('saatlerce', 'ADV'), ('ağlatan', 'VERB'), (',', 'PUNCT'), ('gözyaşlarıyla', 'NOUN'), ('dolu', 'ADJ'), ('...', 'PUNCT')], [('Bunun', 'PRON'), ('için', 'ADP'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('Vajina', 'NOUN'), ('Bölgesi', 'NOUN'), ('\"', 'PUNCT'), ('tabiri', 'NOUN'), ('daha', 'ADV'), ('doğru', 'ADJ'), ('olur', 'AUX'), ('.', 'PUNCT')], [('Ben', 'PRON'), ('hapşırdığım', 'VERB'), ('zaman', 'NOUN'), ('ablam', 'NOUN'), ('çok', 'ADV'), ('güler', 'VERB'), ('.', 'PUNCT')], [('islamiyetgercekleri.org', 'PROPN')], [('Bal', 'NOUN'), (',', 'PUNCT'), ('ana', 'ADJ'), ('maddesini', 'NOUN'), ('teşkil', 'NOUN'), ('eden', 'VERB'), ('meyve', 'NOUN'), ('şekeri', 'NOUN'), ('sayesinde', 'NOUN'), ('şeker', 'NOUN'), ('kamışından', 'NOUN'), ('hemen', 'ADV'), ('hemen', 'ADV'), ('iki', 'NUM'), ('misli', 'ADV'), ('daha', 'ADV'), ('tatlıdır', 'ADJ'), ('.', 'PUNCT')], [(\"Sevgi'nin\", 'PROPN'), ('TRT', 'PROPN'), ('yarışmasına', 'NOUN'), ('gönderdiği', 'VERB'), ('Yürümek', 'PROPN'), ('romanını', 'NOUN'), ('sevdim', 'VERB'), ('.', 'PUNCT')], [('Yerli', 'ADJ'), ('kadınlar', 'NOUN'), ('sac', 'NOUN'), ('üzerinde', 'NOUN'), ('kızartılan', 'VERB'), ('yassı', 'ADJ'), ('ekmeklerin', 'NOUN'), ('pişirilmesini', 'VERB'), ('gösteriyorlar', 'VERB'), ('.', 'PUNCT')], [('Aynı', 'ADJ'), ('roman', 'NOUN'), ('Tunç', 'PROPN'), ('Okan', 'PROPN'), ('tarafından', 'NOUN'), ('sinemaya', 'NOUN'), ('uyarlandı', 'VERB'), ('(', 'PUNCT'), ('1993', 'NUM'), (')', 'PUNCT'), ('.', 'PUNCT')], [('Gündüz', 'PROPN'), ('Sevilgen', 'PROPN'), ('adlı', 'ADJ'), (',', 'PUNCT'), (\"MSP'li\", 'ADJ'), ('mühendis', 'NOUN'), (',', 'PUNCT'), (\"CHP'ye\", 'PROPN'), ('yönelttiği', 'VERB'), ('suçlamalarda', 'NOUN'), (',', 'PUNCT'), ('partisi', 'NOUN'), ('için', 'ADP'), ('ün', 'NOUN'), ('yapmaya', 'VERB'), ('başlamıştı', '_'), ('başlamış', 'VERB'), ('tı', 'AUX'), ('bile', 'ADV'), ('.', 'PUNCT')], [('\"', 'PUNCT'), ('Anlaşıldı', 'VERB'), (',', 'PUNCT'), ('tamam', 'INTJ'), ('.', 'PUNCT'), ('\"', 'PUNCT')], [('Kriz', 'NOUN'), ('merkezine', 'NOUN'), ('gelen', 'VERB'), ('bir', 'DET'), ('ihbar', 'NOUN'), ('üzerine', 'NOUN'), (',', 'PUNCT'), ('deponun', 'NOUN'), ('sorumluluğu', 'NOUN'), ('Kocaeli', 'PROPN'), ('Üniversitesi', 'NOUN'), ('Tıp', 'NOUN'), ('Fakültesi', 'NOUN'), ('personeline', 'NOUN'), ('devredildi', 'VERB'), ('.', 'PUNCT')], [('Tilki', 'NOUN'), (',', 'PUNCT'), ('sanki', 'ADV'), ('bir', 'DET'), ('an', 'NOUN'), (\"Ceren'e\", 'PROPN'), ('gülümsedi', 'VERB'), ('.', 'PUNCT')], [('Yayıncılar', 'NOUN'), (',', 'PUNCT'), ('editörler', 'NOUN'), (',', 'PUNCT'), ('şaşılacak', 'VERB'), ('şey', 'NOUN'), (',', 'PUNCT'), ('röntgen', 'NOUN'), ('gibi', 'ADP'), ('biliyorlar', 'VERB'), ('birbirlerini', 'PRON'), ('...', 'PUNCT')], [('Profesyonel', 'ADJ'), ('liglerde', 'NOUN'), ('takımı', 'NOUN'), ('bulunmayan', 'VERB'), ('illerin', 'NOUN'), ('1', 'NUM'), ('.', 'PUNCT')], [('Yenilikleri', 'NOUN'), ('yakından', 'NOUN'), ('izliyordu', '_'), ('izliyor', 'VERB'), ('du', 'AUX'), (';', 'PUNCT'), (\"1974'te\", 'NUM'), ('disco', 'PROPN'), ('music', 'PROPN'), ('akımına', 'NOUN'), ('kapılmış', 'VERB'), ('gördük', 'VERB'), (\"Dalida'yı\", 'PROPN'), ('.', 'PUNCT')]]\n"
     ]
    }
   ],
   "source": [
    "print(posTags[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f8c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<UNK>': 1, '<NUM>': 2, '<_>': 3, '<NOUN>': 4, '<AUX>': 5, '<PUNCT>': 6, '<ADV>': 7, '<PRON>': 8, '<VERB>': 9, '<DET>': 10, '<PROPN>': 11, '<ADJ>': 12, '<CCONJ>': 13, '<ADP>': 14, '<PART>': 15, '<SCONJ>': 16, '<INTJ>': 17, '<X>': 18}\n"
     ]
    }
   ],
   "source": [
    "print(posDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1dfb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the training and validation data files using the `parse_file` function\n",
    "training_data = parse_file(\"./dataset/train.conllu\")\n",
    "validation_data = parse_file(\"./dataset/val.conllu\")\n",
    "\n",
    "\n",
    "# Build the vocabulary for the training data using the `build_vocab` function\n",
    "# The `build_vocab` function returns two dictionaries:\n",
    "#   - `word_to_idx`: maps words to their index in the vocabulary\n",
    "#   - `pos_to_idx`: maps POS tags to their index in the vocabulary\n",
    "word_to_idx, pos_to_idx = build_vocab(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fecd2759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions to convert between indices and human-readable format. You don't need to do anything here.\n",
    "#Just reading and making sure you understand what's going on is enough.\n",
    "\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "idx_to_pos = {idx: pos for pos, idx in pos_to_idx.items()}\n",
    "\n",
    "def convert_idx_to_words(indices: torch.tensor) -> str:\n",
    "    \"\"\"Converts a sequence of word indices to a human-readable format.\n",
    "    \n",
    "    Args:\n",
    "        indices (torch.tensor): A sequence of word indices.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string representation of the sequence of words.\n",
    "    \"\"\"\n",
    "    return \" \".join([idx_to_word[idx.item()] for idx in indices])\n",
    "\n",
    "def convert_idx_to_pos(indices: torch.tensor) -> str:\n",
    "    \"\"\"Converts a sequence of POS tag indices to a human-readable format.\n",
    "    \n",
    "    Args:\n",
    "        indices (torch.tensor): A sequence of POS tag indices.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string representation of the sequence of POS tags.\n",
    "    \"\"\"\n",
    "    return \" \".join([idx_to_pos[idx.item()] for idx in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8330e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD> <UNK> 1936 yılındayız'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indices = torch.tensor([0, 1, 2, 3], dtype=torch.long)\n",
    "\n",
    "convert_idx_to_words(word_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43298805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD> <UNK> <NUM> <_>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_idx_to_pos(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "851cf6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function used for minibatching. You don't need to do anything here. Just reading and making sure you understand what's going on is enough.\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\"\n",
    "    This function collates a batch of sentences into a padded tensor that can be processed by the model.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "    batch: a list of tuples where each tuple contains a sentence and its corresponding POS tags.\n",
    "    Returns:\n",
    "\n",
    "    A tuple of two padded tensors: one containing the text data and the other containing the POS tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_list, text_list = [], []\n",
    "    for (line, label) in batch:\n",
    "        text_list.append(line)\n",
    "        tag_list.append(label)\n",
    "        \n",
    "    return (\n",
    "        pad_sequence(text_list, padding_value=word_to_idx['<PAD>']).t(),\n",
    "        pad_sequence(tag_list, padding_value=pos_to_idx['<PAD>']).t()\n",
    "    )\n",
    "\n",
    "#I havve transposed the outputs since old function do not store sentences in single tensors,\n",
    "#sentence indexes are columns but it will be better to pass them as rows. Also accuracy goes from %93 to %99.5\n",
    "#since storing sentences in single sensors allows to capture context of sentences better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f0ea1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_data = [\n",
    "    (torch.tensor([1, 2, 3, 4]), torch.tensor([1, 2, 1, 2])),  # (sentence, POS tags)\n",
    "    (torch.tensor([5, 6, 7]), torch.tensor([3, 1, 2])),\n",
    "    (torch.tensor([8, 9]), torch.tensor([1, 3]))\n",
    "]\n",
    "\n",
    "text_tensor, pos_tensor = collate_batch(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d47210f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 2],\n",
       "        [3, 1, 2, 0],\n",
       "        [1, 3, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af202881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 0],\n",
       "        [8, 9, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d218c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fd226af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A class representing a Part-Of-Speech (POS) tagging dataset, which inherits from PyTorch's Dataset class.\n",
    "    You need to four methods for this class:\n",
    "    - __init__: Initializes the dataset object.\n",
    "    - __len__: Returns the number of sentences in the dataset.\n",
    "    - __getitem__: Returns the i-th sentence in the dataset.\n",
    "    - vocab_lookup: Converts a sentence represented as a list of word/POS-tag pairs (tuples) to a pair of PyTorch tensors \n",
    "                    representing the corresponding sequences of word and POS tag indices. Out of vocabulary words are\n",
    "                    represented by the index of the \"<UNK>\" token.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: List[List[Tuple[str, str]]], word_to_idx: Dict, pos_to_idx: Dict):\n",
    "        \"\"\"\n",
    "        Initializes a new POSDataset object.\n",
    "        Args:\n",
    "        - data: A list of sentences, where each sentence is a list of word/POS-tag pairs (tuples).\n",
    "        - word_to_idx: A dictionary mapping words to their corresponding indices.\n",
    "        - pos_to_idx: A dictionary mapping POS tags to their corresponding indices.\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE*****\n",
    "        \n",
    "        self.data = data\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.pos_to_idx = pos_to_idx\n",
    "\n",
    "\n",
    "        # *****END OF YOUR CODE*****\n",
    "\n",
    "    def vocab_lookup(self, sentence: List[Tuple[str, str]]) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        Converts a sentence represented as a list of word/POS-tag pairs (tuples) to a pair of PyTorch tensors\n",
    "        representing the corresponding sequences of word and POS tag indices. Out of vocabulary words are\n",
    "        represented by the index of the \"<UNK>\" token.\n",
    "\n",
    "        Args:\n",
    "        - sentence: A list of word/POS-tag pairs (tuples) representing a single sentence.\n",
    "\n",
    "        Returns:\n",
    "        A tuple containing two PyTorch tensors, the first representing the sequence of word indices in the sentence,\n",
    "        and the second representing the sequence of POS tag indices in the sentence.\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE*****\n",
    "        \n",
    "        \n",
    "        wordIndices = torch.empty(len(sentence), dtype=torch.long)\n",
    "        posIndices = torch.empty(len(sentence), dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        for i in range(len(sentence)):\n",
    "            \n",
    "            \n",
    "            if sentence[i][0] in self.word_to_idx:\n",
    "                wordIndices[i] = self.word_to_idx[sentence[i][0]]\n",
    "                posIndices[i] = self.pos_to_idx['<' + sentence[i][1] + '>']\n",
    "            else:\n",
    "                wordIndices[i] = self.word_to_idx[\"<UNK>\"]\n",
    "                posIndices[i] = self.pos_to_idx[\"<UNK>\"]\n",
    "        \n",
    "\n",
    "        return wordIndices, posIndices\n",
    "    \n",
    "        # *****END OF YOUR CODE*****\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of sentences in the dataset.\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE*****\n",
    "        \n",
    "        return len(self.data)\n",
    "        # *****END OF YOUR CODE*****\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        Returns a single sentence from the dataset as a pair of PyTorch tensors representing the corresponding\n",
    "        sequences of word and POS tag indices.\n",
    "\n",
    "        Args:\n",
    "        - idx: The index of the sentence to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        A tuple containing two PyTorch tensors, the first representing the sequence of word indices in the sentence,\n",
    "        and the second representing the sequence of POS tag indices in the sentence.\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE*****\n",
    "        \n",
    "        return self.vocab_lookup(self.data[idx])\n",
    "\n",
    "        # *****END OF YOUR CODE*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41b06539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<UNK>': 1, '<NUM>': 2, '<_>': 3, '<NOUN>': 4, '<AUX>': 5, '<PUNCT>': 6, '<ADV>': 7, '<PRON>': 8, '<VERB>': 9, '<DET>': 10, '<PROPN>': 11, '<ADJ>': 12, '<CCONJ>': 13, '<ADP>': 14, '<PART>': 15, '<SCONJ>': 16, '<INTJ>': 17, '<X>': 18}\n"
     ]
    }
   ],
   "source": [
    "posDS = POSDataset(posTags ,word_to_idx, pos_to_idx)\n",
    "\n",
    "print(posDS.pos_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e55c3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,  6]),\n",
       " tensor([8, 7, 9, 9, 9, 4, 8, 4, 9, 9, 4, 3, 4, 5, 6]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posDS.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36712911",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "328c86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is preparing the training and validation datasets by creating POSDataset objects \n",
    "# using training_data and validation_data. The word_to_idx and pos_to_idx dictionaries created in build_vocab \n",
    "# are passed to POSDataset so that each sentence in the datasets can be converted to a tensor of word and POS tag indices.\n",
    "# Then, DataLoader objects are created for both the training and validation datasets, with BATCH_SIZE batches per iteration. \n",
    "# shuffle=True is used to shuffle the order of samples in each batch, which helps to prevent the model from overfitting to the order of the data. \n",
    "# collate_batch is used as the function to merge samples into batches, as it pads sequences to the same length and \n",
    "# returns two tensors, one for the word indices and one for the POS tag indices.\n",
    "# This code block is essential to prepare the data for training the model. \n",
    "# The training and validation dataloaders can be used in the training loop to iterate over the dataset in batches.\n",
    "\n",
    "rawTrainData = parse_file(\"dataset/train.conllu\")\n",
    "rawValidationData = parse_file(\"dataset/val.conllu\")\n",
    "\n",
    "training_dataset = [[0 for i in range(len(rawTrainData))] for j in range(len(rawTrainData))]\n",
    "validation_dataset = [[0 for i in range(len(rawValidationData))] for j in range(len(rawValidationData))]\n",
    "\n",
    "\n",
    "for i in range(len(rawTrainData)):\n",
    "    training_dataset[i] = posDS.__getitem__(i)\n",
    "\n",
    "for i in range(len(rawValidationData)):\n",
    "    validation_dataset[i] = posDS.__getitem__(i)\n",
    "\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5947ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in word vocabulary: 33488\n",
      "Unique tokens in tag vocabulary: 19\n",
      "\n",
      "Number of training examples: 7803\n",
      "Number of validation examples: 979\n"
     ]
    }
   ],
   "source": [
    "# It is always usefull to see dataset statistics to get a better understanding of the data.\n",
    "print(f\"Unique tokens in word vocabulary: {len(word_to_idx)}\")\n",
    "print(f\"Unique tokens in tag vocabulary: {len(pos_to_idx)}\")\n",
    "print()\n",
    "print(f\"Number of training examples: {len(training_dataset)}\")\n",
    "print(f\"Number of validation examples: {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28217969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39, 40, 41, 42, 43, 44,  6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d913300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from the dataset: (tensor([39, 40, 41, 42, 43, 44,  6]), tensor([4, 7, 7, 3, 9, 5, 6]))\n",
      "\n",
      "Human-readable version: Rüzgâr yine güçlü esiyordu esiyor du . <NOUN> <ADV> <ADV> <_> <VERB> <AUX> <PUNCT>\n"
     ]
    }
   ],
   "source": [
    "# Check a random sample from the training dataset to see if the data is correctly loaded.\n",
    "print(\"Sample from the dataset:\", training_dataset[4])\n",
    "print()\n",
    "print(\"Human-readable version:\", convert_idx_to_words(training_dataset[4][0]), convert_idx_to_pos(training_dataset[4][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a7b571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3,  4,  5,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 7,  8,  9, 10, 11, 12, 13,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,  6,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,  6,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [39, 40, 41, 42, 43, 44,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [45, 46, 47, 48, 49, 30, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 10,\n",
       "         61, 62, 63,  6],\n",
       "        [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [76, 77, 78, 79, 80, 81,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_batch(training_dataset[0:8])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f8e11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        \"\"\"\n",
    "        BiLSTM model for POS tagging.\n",
    "        Check this link for more details: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of unique words in the vocabulary.\n",
    "            embedding_dim (int): Dimension of the word embeddings.\n",
    "            hidden_dim (int): Dimension of the LSTM hidden states.\n",
    "            output_dim (int): Number of unique POS tags.\n",
    "            n_layers (int): Number of LSTM layers.\n",
    "            bidirectional (bool): Whether to use a bidirectional LSTM.\n",
    "            dropout (float): Probability of dropout, if any.\n",
    "            pad_idx (int): Index of the <PAD> token in the vocabulary.\n",
    "            embed_model (fasttext.FastText._FastText): FastText embedding model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # *****START OF YOUR CODE*****\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.output_layer = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # *****END OF YOUR CODE*****\n",
    "\n",
    "    def forward(self, text):\n",
    "        \"\"\"\n",
    "        Perform forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            text (Tensor): Input text of shape [batch size, sent len].\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Predictions of shape [batch size, sent len, output dim].\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE*****\n",
    "        \n",
    "        if len(text.shape) == 1:\n",
    "            text = text.unsqueeze(0)\n",
    "\n",
    "        \n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        embedded = embedded.permute(1, 0, 2)  # Shape: [sent len, batch size, embedding dim]\n",
    "\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        lstm_out = lstm_out.permute(1, 0, 2)\n",
    "\n",
    "        predictions = self.output_layer(lstm_out)\n",
    "\n",
    "    \n",
    "\n",
    "        return predictions\n",
    "\n",
    "        # *****END OF YOUR CODE*****\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9906c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate_batch(training_dataset[0:8])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce23dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posTaggerLstm  = BiLSTMPOSTagger(len(word_to_idx), 50, 50, len(pos_to_idx), 1, False, 0, pos_to_idx['<PAD>'])\n",
    "\n",
    "#def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx, embed_model):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "449cc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#posTaggerLstm.forward(collate_batch(training_dataset[0:8])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a23b7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#posTaggerLstm.forward(training_dataset[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecb7d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = posTaggerLstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68403c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-4.2129e-02,  1.0989e-01,  1.8281e-02, -5.7311e-02,  1.2267e-01,\n",
      "           9.3718e-02,  5.5838e-02, -3.4160e-02,  7.7673e-02,  1.1884e-02,\n",
      "           1.6854e-01, -4.3238e-02,  6.2788e-02, -9.8674e-02, -1.3750e-01,\n",
      "           1.1036e-02, -4.7391e-02,  1.7808e-02,  1.1277e-04],\n",
      "         [-6.3688e-02,  4.1358e-02,  6.6684e-02, -1.3199e-01,  1.9956e-01,\n",
      "           8.4090e-02,  7.9731e-02, -5.8043e-02,  1.1977e-01, -7.1021e-02,\n",
      "           1.9334e-01, -4.2557e-02,  4.0058e-02, -6.1211e-02, -8.1300e-02,\n",
      "          -2.8200e-02, -5.8278e-02,  1.2436e-01,  1.0911e-02],\n",
      "         [-1.1930e-02,  1.3219e-01,  2.2362e-02, -5.0677e-02,  2.7502e-01,\n",
      "           2.3505e-01,  1.6743e-01,  5.0217e-02,  1.3256e-01, -2.8351e-02,\n",
      "           2.1266e-01,  2.7879e-02,  2.9687e-02, -1.1512e-01, -1.6101e-01,\n",
      "          -7.6815e-02, -3.4698e-02,  9.5025e-02, -6.1736e-02],\n",
      "         [-3.4344e-02,  4.7601e-02,  5.6045e-02, -1.0110e-01,  2.3332e-01,\n",
      "           1.9335e-01,  1.3995e-01,  8.0567e-02,  1.1499e-01, -7.9197e-02,\n",
      "           3.2312e-01, -1.3048e-02,  7.6819e-02, -6.1837e-02, -1.9355e-01,\n",
      "          -4.8171e-02,  3.9100e-02,  1.4870e-01, -6.8451e-02],\n",
      "         [-1.0444e-01,  7.0224e-02,  7.8374e-02, -7.1059e-02,  1.8949e-01,\n",
      "           2.1501e-01,  9.3816e-02,  2.1353e-02, -4.8089e-02,  7.1571e-02,\n",
      "           2.1471e-01,  4.0996e-02, -9.2676e-02, -3.7743e-03, -2.0589e-01,\n",
      "           6.2475e-02, -2.7912e-02,  1.2913e-02,  8.6734e-03],\n",
      "         [-1.4169e-01,  9.2736e-02, -1.2797e-01, -2.3260e-01,  7.2948e-02,\n",
      "           3.2047e-02,  1.1182e-01,  6.6785e-02,  1.7979e-01, -2.3553e-02,\n",
      "           1.8215e-01, -1.7668e-02,  6.5537e-02, -5.6291e-02, -7.3022e-02,\n",
      "           1.3370e-01,  1.1231e-01,  1.4696e-01, -1.3701e-01],\n",
      "         [-1.1776e-01,  2.0023e-02,  5.4136e-02, -2.2770e-01,  1.7180e-01,\n",
      "           2.0485e-02,  1.3568e-01,  1.1169e-01, -3.5411e-02,  2.7027e-02,\n",
      "           1.5645e-01, -8.7274e-02,  1.7508e-01, -8.8966e-02, -9.4217e-02,\n",
      "           8.1010e-02, -3.4475e-03,  2.0182e-01, -1.0541e-01],\n",
      "         [-6.1144e-02,  5.8503e-02,  1.7501e-01, -1.7346e-01,  1.7040e-01,\n",
      "          -2.6134e-02,  1.0686e-01,  1.3000e-01, -4.6261e-02, -8.9002e-02,\n",
      "           1.4724e-01, -1.9699e-01,  1.0429e-01, -3.5919e-02, -1.8634e-01,\n",
      "           1.6336e-01, -2.9512e-02,  6.9049e-02, -1.2854e-02]]])\n"
     ]
    }
   ],
   "source": [
    "# See the output of the model for a random sample from the training dataset.\n",
    "# It is wrapped in torch.no_grad() because we are not training the model.\n",
    "with torch.no_grad():\n",
    "    inputs = training_dataset[1][0]\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35eea10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  8,  9, 10,  3,  4,  5,  6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83c8be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters\n",
    "\n",
    "NUM_OF_EPOCHS = 10\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84fd9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pos_to_idx['<PAD>']) #Modify this part if you are using a different padding token.\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00faaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_single_epoch(model, iterator, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch on the given iterator with the specified optimizer and criterion.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model to train.\n",
    "        iterator: The iterator over the training dataset.\n",
    "        optimizer: The optimizer to use for gradient descent.\n",
    "        criterion: The loss function to use.\n",
    "        tag_pad_idx: The index of the padding token in the tag vocabulary.\n",
    "        tag_unk_idx: The index of the unknown token in the tag vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        The average loss and accuracy for the epoch.\n",
    "    \"\"\"\n",
    "    # *****START OF YOUR CODE*****\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for text, tags in iterator:\n",
    "        text = text.to(device)\n",
    "        tags = tags.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text)\n",
    "        reshaped_preds = predictions.view(-1, predictions.shape[-1])\n",
    "        reshaped_tags = tags.reshape(-1)\n",
    "\n",
    "        mask = (reshaped_tags != pos_to_idx['<PAD>'])\n",
    "        loss = criterion(reshaped_preds[mask], reshaped_tags[mask])\n",
    "\n",
    "        acc = categorical_accuracy(predictions, tags, pos_to_idx['<PAD>'])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "    # *****END OF YOUR CODE*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0581ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns the categorical accuracy between predictions and the ground truth, ignoring pad tokens.\n",
    "    \"\"\"\n",
    "    # *****START OF YOUR CODE*****\n",
    "    \n",
    "    max_preds = preds.argmax(dim=-1)\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero(as_tuple=True)\n",
    "    \n",
    "    correct_preds = max_preds[non_pad_elements]\n",
    "    correct_tags = y[non_pad_elements]\n",
    "    \n",
    "    correct = correct_preds.eq(correct_tags).sum()\n",
    "    total = len(correct_tags)\n",
    "\n",
    "    return correct.float() / total\n",
    "\n",
    "    # *****END OF YOUR CODE*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47f2f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a BiLSTMPOSTagger model on a given dataset iterator. Use the categorical_accuracy function\n",
    "    you implemented above to calculate the accuracy on a batch of predictions.\n",
    "\n",
    "    Args:\n",
    "    - model: a BiLSTMPOSTagger object.\n",
    "    - iterator: a DataLoader object containing (text, tags) tuples.\n",
    "    - tag_pad_idx: an integer representing the index of the padding token in the tag vocabulary.\n",
    "\n",
    "    Returns:\n",
    "    - A float representing the categorical accuracy of the model on the given dataset iterator.\n",
    "\n",
    "    \"\"\"\n",
    "    # *****START OF YOUR CODE*****\n",
    "    \n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text, tags in iterator:\n",
    "            text = text.to(device)\n",
    "            tags = tags.to(device)\n",
    "\n",
    "            predictions = model(text)\n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_acc / len(iterator)\n",
    "\n",
    "    # *****END OF YOUR CODE*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad712f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training: 10.46%\n"
     ]
    }
   ],
   "source": [
    "# Check the models accuracy without training\n",
    "accuracy = evaluate(model, validation_dataloader, tag_pad_idx=pos_to_idx['<PAD>'])\n",
    "print(f'Accuracy before training: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4aaf693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random predictions: 5.73%\n",
      "Most frequent tag: 4\n",
      "Accuracy of predicting the most frequent class: 30.71%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def random_model(text):\n",
    "    with torch.no_grad():\n",
    "        # Get the input tensor shape\n",
    "        input_shape = model(text).shape\n",
    "        # Create the logits tensor with the same shape\n",
    "        logits = torch.zeros(*input_shape, dtype=torch.float32, device=text.device)\n",
    "        # Create random predictions\n",
    "        random_preds = torch.randint(len(pos_to_idx), input_shape[:-1], device=text.device)\n",
    "        logits.scatter_(2, random_preds.unsqueeze(2), 1)\n",
    "        \n",
    "    return logits\n",
    "\n",
    "random_accuracy = evaluate(random_model, validation_dataloader, tag_pad_idx=pos_to_idx['<PAD>'])\n",
    "print(f'Accuracy of random predictions: {random_accuracy*100:.2f}%')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_counter = Counter()\n",
    "for _, tags in training_dataloader:\n",
    "    tag_counter.update(tags.reshape(-1).tolist())\n",
    "\n",
    "del tag_counter[pos_to_idx['<PAD>']]\n",
    "\n",
    "most_frequent_tag = tag_counter.most_common(1)[0][0]\n",
    "print(f\"Most frequent tag: {most_frequent_tag}\")\n",
    "\n",
    "epoch_correct = epoch_n_label = 0\n",
    "\n",
    "for text, tags in validation_dataloader:\n",
    "    text = text.to(device)\n",
    "    tags = tags.to(device)\n",
    "\n",
    "    most_frequent_preds = torch.full_like(tags, fill_value=most_frequent_tag)\n",
    "\n",
    "    mask = (tags != pos_to_idx['<PAD>'])\n",
    "    correct = most_frequent_preds.eq(tags).masked_select(mask).sum().item()\n",
    "    n_label = mask.sum().item()\n",
    "\n",
    "    epoch_correct += correct\n",
    "    epoch_n_label += n_label\n",
    "\n",
    "most_frequent_accuracy = epoch_correct / epoch_n_label\n",
    "print(f'Accuracy of predicting the most frequent class: {most_frequent_accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2b6ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters\n",
    "\n",
    "NUM_OF_EPOCHS = 10\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97cefe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pos_to_idx['<PAD>']) #Modify this part if you are using a different padding token.\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9e5684a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Training Loss: 1.171 | Training Acc: 62.77% | Validation Acc: 77.82%\n",
      "Epoch: 02 | Training Loss: 0.615 | Training Acc: 80.72% | Validation Acc: 88.31%\n",
      "Epoch: 03 | Training Loss: 0.331 | Training Acc: 89.99% | Validation Acc: 94.52%\n",
      "Epoch: 04 | Training Loss: 0.185 | Training Acc: 94.33% | Validation Acc: 96.28%\n",
      "Epoch: 05 | Training Loss: 0.119 | Training Acc: 96.20% | Validation Acc: 97.69%\n",
      "Epoch: 06 | Training Loss: 0.084 | Training Acc: 97.28% | Validation Acc: 98.12%\n",
      "Epoch: 07 | Training Loss: 0.062 | Training Acc: 97.98% | Validation Acc: 98.77%\n",
      "Epoch: 08 | Training Loss: 0.049 | Training Acc: 98.43% | Validation Acc: 98.95%\n",
      "Epoch: 09 | Training Loss: 0.040 | Training Acc: 98.67% | Validation Acc: 99.12%\n",
      "Epoch: 10 | Training Loss: 0.034 | Training Acc: 98.85% | Validation Acc: 99.33%\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for x in range(NUM_OF_EPOCHS):\n",
    "    # Call the train_for_single_epoch function and store the result in the training_loss variable.\n",
    "    # Call the evaluate function and store the result in the validation_accuracy variable.\n",
    "    # Print out the current epoch number, training loss, and validation accuracy using the print function and formatted string syntax. \n",
    "    # Apend the training_loss and validation_accuracy values to their respective history lists (loss_history and accuracy_history).\n",
    "    # *****START OF YOUR CODE*****\n",
    "    training_loss, training_accuracy = train_for_single_epoch(model, training_dataloader, optimizer, criterion, device)\n",
    "    validation_accuracy = evaluate(model, validation_dataloader, pos_to_idx['<PAD>'])\n",
    "    \n",
    "    print(f'Epoch: {x+1:02} | Training Loss: {training_loss:.3f} | Training Acc: {training_accuracy*100:.2f}% | Validation Acc: {validation_accuracy*100:.2f}%')\n",
    "    \n",
    "    loss_history.append(training_loss)\n",
    "    accuracy_history.append(validation_accuracy)\n",
    "    \n",
    "\n",
    "    # *****END OF YOUR CODE*****\n",
    "    \n",
    "# Accuracy increses dramatically even after first training.\n",
    "#I think this is related to most words have a few (most of them is porbably 1) possible pos tag, so in the first iteeration model lerns themm, then it starts to learn contextual ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f460dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To plot the training metrics, use the matplotlib library.\n",
    "\n",
    "# *****START OF YOUR CODE*****\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(loss_history, label='Training Loss', color='blue')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.plot(accuracy_history, label='Validation Accuracy', color='red')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Training Loss and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# *****END OF YOUR CODE*****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60abf3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training: 99.33%\n"
     ]
    }
   ],
   "source": [
    "# Check the models accuracy without training\n",
    "accuracy = evaluate(model, validation_dataloader, tag_pad_idx=pos_to_idx['<PAD>'])\n",
    "print(f'Accuracy before training: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b700fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicallyEmbeddedPOSTagger(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx, embed_model):\n",
    "        \"\"\"\n",
    "        BiLSTM model for POS tagging.\n",
    "        Check this link for more details: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of unique words in the vocabulary.\n",
    "            embedding_dim (int): Dimension of the word embeddings.\n",
    "            hidden_dim (int): Dimension of the LSTM hidden states.\n",
    "            output_dim (int): Number of unique POS tags.\n",
    "            n_layers (int): Number of LSTM layers.\n",
    "            bidirectional (bool): Whether to use a bidirectional LSTM.\n",
    "            dropout (float): Probability of dropout, if any.\n",
    "            pad_idx (int): Index of the <PAD> token in the vocabulary.\n",
    "            embed_model (fasttext.FastText._FastText): FastText embedding model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embed_model = embed_model\n",
    "        self.embedding = nn.Parameter(torch.zeros(input_dim, embedding_dim), requires_grad=False)\n",
    "        \n",
    "        # set the values of the embedding tensor to the values of the FastText embedding model\n",
    "        for i in range(len(idx_to_word)):\n",
    "            token = idx_to_word[i]\n",
    "            if token in self.embed_model:\n",
    "                self.embedding.data[i] = torch.tensor(self.embed_model[token], dtype=torch.float)        \n",
    "        \n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        \"\"\"\n",
    "        Perform forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            text (Tensor): Input text of shape [batch size, sent len].\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Predictions of shape [batch size, sent len, output dim].\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE*****\n",
    "        if len(text.shape) == 1:\n",
    "        # Add singleton dimension to create a batch of 1\n",
    "            text = text.unsqueeze(0)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.embedding[text]\n",
    "\n",
    "        # Apply dropout\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # Permute dimensions to match the expected input shape for LSTM\n",
    "        embedded = embedded.permute(1, 0, 2)  # Shape: [sent len, batch size, embedding dim]\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "\n",
    "        # Apply dropout\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # Permute dimensions back to [batch size, sent len, hidden_dim * num_directions]\n",
    "        lstm_out = lstm_out.permute(1, 0, 2)\n",
    "\n",
    "        # Fully connected layer\n",
    "        predictions = self.fc(lstm_out)\n",
    "\n",
    "    \n",
    "\n",
    "        return predictions\n",
    "\n",
    "        # *****END OF YOUR CODE*****\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0163afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamicallyEmbeddedTagger  = DynamicallyEmbeddedPOSTagger(len(word_to_idx), 100, 50, len(pos_to_idx), 2, True, 0, pos_to_idx['<PAD>'], embed_model_skipgram)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d4f9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = dynamicallyEmbeddedTagger\n",
    "# Load the FastText pre-trained embeddings and set them as the model's embedding layer\n",
    "# pretrained_embeddings = None\n",
    "# model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80334f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters\n",
    "\n",
    "NUM_OF_EPOCHS = 10\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1cf23ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pos_to_idx['<PAD>'])\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e2b9c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Training Loss: 1.471 | Training Acc: 51.43% | Validation Acc: 60.67%\n",
      "Epoch: 02 | Training Loss: 1.177 | Training Acc: 60.11% | Validation Acc: 62.53%\n",
      "Epoch: 03 | Training Loss: 1.120 | Training Acc: 62.04% | Validation Acc: 64.43%\n",
      "Epoch: 04 | Training Loss: 1.081 | Training Acc: 63.25% | Validation Acc: 65.62%\n",
      "Epoch: 05 | Training Loss: 1.045 | Training Acc: 64.18% | Validation Acc: 66.24%\n",
      "Epoch: 06 | Training Loss: 1.013 | Training Acc: 65.26% | Validation Acc: 67.94%\n",
      "Epoch: 07 | Training Loss: 0.981 | Training Acc: 66.22% | Validation Acc: 68.67%\n",
      "Epoch: 08 | Training Loss: 0.949 | Training Acc: 67.32% | Validation Acc: 69.75%\n",
      "Epoch: 09 | Training Loss: 0.920 | Training Acc: 68.25% | Validation Acc: 71.34%\n",
      "Epoch: 10 | Training Loss: 0.891 | Training Acc: 69.20% | Validation Acc: 72.60%\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for x in range(NUM_OF_EPOCHS):\n",
    "    # Call the train_for_single_epoch function and store the result in the training_loss variable.\n",
    "    # Call the evaluate function and store the result in the validation_accuracy variable.\n",
    "    # Print out the current epoch number, training loss, and validation accuracy using the print function and formatted string syntax. \n",
    "    # Apend the training_loss and validation_accuracy values to their respective history lists (loss_history and accuracy_history).\n",
    "    \n",
    "    # *****START OF YOUR CODE*****\n",
    "    training_loss, training_accuracy = train_for_single_epoch(model, training_dataloader, optimizer, criterion, device)\n",
    "    validation_accuracy = evaluate(model, validation_dataloader, pos_to_idx['<PAD>'])\n",
    "    \n",
    "    print(f'Epoch: {x+1:02} | Training Loss: {training_loss:.3f} | Training Acc: {training_accuracy*100:.2f}% | Validation Acc: {validation_accuracy*100:.2f}%')\n",
    "    \n",
    "    loss_history.append(training_loss)\n",
    "    accuracy_history.append(validation_accuracy)\n",
    "    \n",
    "\n",
    "    # *****END OF YOUR CODE*****\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33232f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves\n",
    "# *****START OF YOUR CODE*****\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(loss_history, label='Training Loss', color='blue')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.plot(accuracy_history, label='Validation Accuracy', color='red')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Training Loss and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# *****END OF YOUR CODE*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572beed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
